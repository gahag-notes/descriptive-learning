# -*- after-save-hook: org-latex-export-to-pdf; -*-
#+latex_header: \usepackage[margin=2cm]{geometry}
#+latex_header: \usepackage{enumitem}
#+latex_header: \setlength{\parindent}{0cm}

#+title: Aprendizado Descritivo
#+options: date:nil

* Definição
  Aprendizado descritivo se enquadra na seguinte classificação dos métodos de aprendizado
  de máquina:
  - Aprendizado preditivo: :: supervisionado ou não, tem como objetivo predizer dada
    característica (/target/).
  - Aprendizado descritivo: :: supervisionado ou não, tem como objetivo obter uma
    descrição para os dados.
  Contrastando, o aprendizado preditivo pretende prever dados futuros ou desconhecidos,
  enquando o apredizado descritivo prentende trazer uma instrospecção sobre os dados. Tal
  diferença pode se apresentar de forma tênue. Um exemplo são os algorítmos de
  agrupamento, que podem ser utilizado em ambas formas. Particularmente, o algorítmo
  /K-means/ se apresenta:
  - Preditivo: :: /K-means/: $P \to C$
  - Descritivo: :: /K-means/: $A \to C$
  Em aprendizado preditivo, o /K-means/ possui como domínio toda a população, ainda que o
  treinamento seja realizado apenas com uma amostra. Já no aprendizado descritivo, nos
  limitamos à amostra, afinal ela constitui o alvo total de análise.
* Mineração de itens frequentes
  Para um conjunto de dados:
  #+attr_latex: :options [itemsep=0pt]
  1. Chamamos de itens os elementos do conjunto de variáveis de análise $I$.
  2. Um conjunto $X \subseteq I$ é denominado /itemset/
  3. O conjunto de todos /k/-/itemsets/ é denotado port $I^{(k)}$.
  4. A amostra de transações é denominada por $T$.
  5. Cada transação é identificada unicamente por um =tid=.
  6. Um conjunto $Y \subseteq T$ é denominado /tidset/.
  7. Cada transação consiste de um identificador, e um conjunto de itens:
     $(\text{tid}, X),\> X \subseteq I$

  Formalmente, um conjunto de dados será uma tripla $(T, I, D)$, onde $D \subseteq T \times I$
  é uma relação binária:
  #+begin_export latex
  \[
    (t, i) \in D \iff \big[i \in X \text{ na transação } (t, X)\big]
  \]
  #+end_export
  @@latex:\newpage@@

  Uma transação pode *conter* um /itemset/, e tal relação é definida da seguinte forma:
  #+begin_export latex
  \[
    X \subseteq t \iff \forall\, i \in X: (t, i) \in D
  \]
  #+end_export
  O conjunto de transações que contém um /itemset/ $X$ é denominado *extensão* ou *cobertura* de $X$. \\
  Tal conjunto é definido pela seguinte operação:
  #+begin_export latex
  \begin{align*}
    & c: \mathcal{P}(I) \to \mathcal{P}(T) \\
    & c(X) = \big\{ t \in T \mid \forall\, i \in X: (t, i) \in D \big\}
  \end{align*}
  #+end_export
  Analogamente, o maior conjunto de itens comuns à um /tidset/ $Y$ é chamado de *intensão* de $Y$.
  #+begin_export latex
  \begin{align*}
    & i: \mathcal{P}(T) \to \mathcal{P}(I) \\
    & i(Y) = \big\{ x \in I \mid \forall\, t \in Y: (t, x) \in D \big\}
  \end{align*}
  #+end_export

  Desta forma, podemos representar um conjunto de dados de duas formas:
  - Horizontal: :: o conjunto de transações e suas intesões: $\big\{\big(t, i(t)\big) \mid t \in T \big\}$
  - Vertical : :: o conjunto de itens e suas coberturas: $\big\{\big(x, c(x)\big) \mid x \in I \big\}$
** Metodologia
   A identificação de regras de associação, em geral, envolve duas etapas:
   #+attr_latex: :options [itemsep=0pt]
   1. Mineração de conjuntos de itens frequentes
   2. Descoberta de regras de associação
   Devido à natureza computacionalmente intensa da primeira etapa, nossos estudos a focam. \\

   O limiar que separa os itens frequentes dos infrequentes é chamado de *suporte mínimo*. \\
   O suporte mínimo de um /itemset/ é o tamanho de sua cobertura:
   #+begin_export latex
   \[
     \text{sup}(X) = \big|c(X)\big|
   \]
   #+end_export
   Admite-se também a definição de *suporte relativo*:
   #+begin_export latex
   \[
     \text{rsup}(X) = \frac{\big|c(X)\big|}{|T|}
   \]
   #+end_export
** Algoritmos
   O espaço de busca do problema é o conjunto potência do conjunto de itens. Se
   considerarmos a relação de subconjuntos como uma relação de ordem parcial, temos que o
   espaço de busca é estruturado como um reticulado. Este reticulado pode ser visualizado
   como um grafo, onde somente as relações diretas são representadas.
   #+attr_latex: :options [label=$\to$]
   - Se $A \subseteq B \land |A| = |B| - 1$, então existe uma aresta entre $A$ e $B$.
   Assim, a mineração de conjunto de itens frequentes é resolvida por uma busca neste
   reticulado, seja em largura ou em profundidade. De fato, existem abordagens baseadas em
   ambas as buscas. \\

   No entanto, a maioria das abordagens compartilham a mesma estrutura de busca:
   #+attr_latex: :options [itemsep=0pt]
   1. Identificam candidatos navegando o espaço de busca
   2. Computam o suporte desses candidatos, descartando os infrequentes
   @@latex:\newpage@@
*** Algoritmo ingênuo
    Um algorítmo ingênuo é definido: enumerar cada /itemset/ possível, e verificar no
    conjunto de dados quais transações contêm esse /itemset/.
    #+attr_latex: :options [itemsep=0pt]
    - A computação do suporte de um /itemset/ requer uma passada sobre o conjunto de dados:
      $\mathcal{O}(|T|)$
    - Verificar se uma dada transação contém um /itemset/: $\mathcal{O}(|I|)$
    - Portanto, o custo total de computação do suporte é $\mathcal{O}(|I| \cdot |T|)$
    - O espaço de busca, por sua vez, é o conjunto potência de $I$.
    Logo, a complexidade do algoritmo ingênuo é $\mathcal{O}\big(2^{|I|} \cdot |I| \cdot |T|\big)$. \\

    Vale notar que, devido aos seus tamanhos, a memória principal tipicamente não comporta
    o conjunto de dados. Tal característica agrava fortemente a ineficiência deste
    algorítimo, onde o componente $\mathcal{O}(|I| \cdot |T|)$ corresponde à passadas no
    conjunto de dados.
*** Apriori
    O algoritmo Apriori é viabilizado pela propriedade de *anti-monotonicidade* da função
    suporte:
    #+begin_export latex
    \[
      A \subseteq B \implies \text{sup}(A) \geq \text{sup}(B)
    \]
    #+end_export
    O Apriori utiliza busca em largura para minerar os padrões. A busca inicia com a
    identificação dos itens frequentes. Depois, os conjuntos de tamanho $k$ são explorados
    antes dos imediatamente maiores. Assim como o ingênuo, ele também opera em duas etapas:
    #+attr_latex: :options [itemsep=0pt]
    1. Geração de candidatos
    2. Cálculo do suporte e eliminação dos infrequentes.
    Candidatos que diferem em apenas um item são combinados para gerar os próximos
    candidatos, de tamanho $k + 1$. Imediatamente, os que possuirem algum subconjunto
    infrequente são descartados. Utilizando este método, os suportes dos candidatos são
    atualizados com uma única passada no conjunto de dados. \\

    No total, o número de passadas é drasticamente reduzido: $\mathcal{O}(I)$ \\

    Apesar disso, o algoritmo ainda apresenta problemas:
    #+attr_latex: :options [itemsep=0pt]
    - Nem sempre a memória primária comporta todos candidatos de um nível, demandados para
      busca em largura.
    - As operações de poda e cálculo do suporte podem ser consideravelmente custosas, mas
      podem ser atenuadas com estruturas de dados apropriadas.
    - A redução do suporte mínimo implica um grande impacto no custo computacional, pois
      quanto mais profundo o nível, seu tamanho cresce exponencialmente.
    - A densidade da base de dados também decorre em um custo maior: transações com mais
      itens implicam /itemsets/ maiores, mais subconjuntos são gerados para a contagem do
      suporte.
    @@latex:\newpage@@
*** Equivalence Class Transformation
    O Eclat tem como proposta eliminar a necessidade de passadas no conjunto de dados para
    computar o suporte. Para isso, utiliza-se uma representação vertical dos dados, e o
    fato de que a cobertura da união de dois /itemsets/ é a interseção de suas coberturas. \\

    De forma equivalente, a ideia central do algoritmo é manter os /tidsets/ em memória
    principal para computar o suporte dos /itemsets/ através de interseções desses
    conjuntos. Contudo, a memória principal pode não comportar todos os /tidsets/. Assim, é
    necessário algum mecanismo que possibilite a divisão do espaço de busca em
    subproblemas independentes. \\

    Esta divisão pode ser feita conforme uma relação de equivalência estabelecida sobre os
    candidatos. Seja $p: \mathcal{P}(I) \times N \to \mathcal{P}(I)$ uma função prefixo. A
    seguinte relação é uma relação de equivalência:
    #+begin_export latex
    \begin{align*}
      & \theta_k \subseteq \mathcal{P}(I) \times \mathcal{P} \\
      & A \> \theta_k \> B \equiv p(A, k) = p(B, k)
    \end{align*}
    #+end_export
    Dessa forma, induz-se uma partição dos conjuntos de itens em classes de equivalência,
    onde todos os elementos compartilham um certo prefixo. \\

    Durante a busca em profundidade, o algoritmo particiona os conjuntos de itens conforme
    a relação de equivalência e o nível da árvore. O cálculo do suporte no algoritmo se
    restringe a calcular o tamanho do /tidset/. \\

    Apesar disso, o algoritmo ainda apresenta problemas:
    #+attr_latex: :options [itemsep=0pt]
    - O tempo de execução depende do cálculo da interseção dos /tidsets/.
    - O custo computacional do algoritmo está diretamente relacionado ao tamanho dos
      /tidsets/.
    - O custo de espaço também depende do tamanho. Quanto mais denso o conjunto de dados,
      mais largos serão os /tidsets/.
*** dEclat
    De forma a atacar o problema de espaço do Eclat, podemos substituir os /tidsets/ pela
    diferença entre os mesmos e os prefixos que os definem para os membros de cada
    classe. Tal conjunto é denomidado *diffset*. Para um prefixo $P$ e um /itemset/ $PX$, o
    /diffset/ de $X$ é
    #+begin_export latex
    \[
      d(PX) = c(P) - c(X)
    \]
    #+end_export
    Somente os /diffsets/ são armazenados, portanto o suporte não é mais obtido como a
    cardinalidade desse conjunto. Calculamos o suporte de um itemset $PXY$, obtido a
    partir de $PX$ e $PY$, da seguinte forma:
    #+begin_export latex
    \[
      \text{sup}(PXY) = \text{sup}(PX) - \left|d(PXY)\right|
    \]
    #+end_export
    Tal solução passa por computar o diffset de $PXY$:
    #+begin_export latex
    \[
      d(PXY) = d(PY) - d(PX)
    \]
    #+end_export
    Em outras palavras, podemos usar os diffsets dos conjuntos base para calcular o
    diffset do novo candidato. \\

    Essa abordagem se mostra muito eficiente para conjuntos densos. Porém, em conjuntos
    esparsos, o algoritmo original é a melhor opção.


